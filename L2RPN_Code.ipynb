{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "xC42kmS5cA-t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC42kmS5cA-t",
        "outputId": "6dde4b92-0beb-4ba2-da3e-c4e474692f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grid2op in /usr/local/lib/python3.10/dist-packages (1.10.3)\n",
            "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.10/dist-packages (from grid2op) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from grid2op) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from grid2op) (2.1.4)\n",
            "Requirement already satisfied: pandapower>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from grid2op) (2.14.9)\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.10/dist-packages (from grid2op) (4.66.4)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from grid2op) (3.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from grid2op) (2.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from grid2op) (24.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from grid2op) (4.12.2)\n",
            "Requirement already satisfied: deepdiff in /usr/local/lib/python3.10/dist-packages (from pandapower>=2.2.2->grid2op) (7.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->grid2op) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->grid2op) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->grid2op) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->grid2op) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->grid2op) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->grid2op) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->grid2op) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.3->grid2op) (1.16.0)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff->pandapower>=2.2.2->grid2op) (4.1.0)\n",
            "Requirement already satisfied: l2rpn-baselines in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: grid2op in /usr/local/lib/python3.10/dist-packages (from l2rpn-baselines) (1.10.3)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from l2rpn-baselines) (0.14.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from l2rpn-baselines) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from l2rpn-baselines) (1.26.4)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (from l2rpn-baselines) (0.29.1)\n",
            "Requirement already satisfied: lightsim2grid in /usr/local/lib/python3.10/dist-packages (from l2rpn-baselines) (0.9.0)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->l2rpn-baselines) (2.1.4)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->l2rpn-baselines) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->l2rpn-baselines) (24.1)\n",
            "Requirement already satisfied: pandapower>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from grid2op->l2rpn-baselines) (2.14.9)\n",
            "Requirement already satisfied: tqdm>=4.45.0 in /usr/local/lib/python3.10/dist-packages (from grid2op->l2rpn-baselines) (4.66.4)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from grid2op->l2rpn-baselines) (3.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from grid2op->l2rpn-baselines) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from grid2op->l2rpn-baselines) (4.12.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->l2rpn-baselines) (2.2.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium->l2rpn-baselines) (0.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightsim2grid->l2rpn-baselines) (71.0.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from lightsim2grid->l2rpn-baselines) (24.1.2)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from lightsim2grid->l2rpn-baselines) (2.13.1)\n",
            "Requirement already satisfied: deepdiff in /usr/local/lib/python3.10/dist-packages (from pandapower>=2.2.2->grid2op->l2rpn-baselines) (7.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels>=0.11.1->l2rpn-baselines) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels>=0.11.1->l2rpn-baselines) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels>=0.11.1->l2rpn-baselines) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.11.1->l2rpn-baselines) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->grid2op->l2rpn-baselines) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->grid2op->l2rpn-baselines) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->grid2op->l2rpn-baselines) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->grid2op->l2rpn-baselines) (2024.7.4)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff->pandapower>=2.2.2->grid2op->l2rpn-baselines) (4.1.0)\n",
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.3.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable_baselines3) (12.6.20)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: lightsim2grid in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightsim2grid) (71.0.4)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from lightsim2grid) (24.1.2)\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from lightsim2grid) (2.13.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightsim2grid) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightsim2grid) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightsim2grid) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "#installing libraries\n",
        "!pip install grid2op\n",
        "!pip install l2rpn-baselines\n",
        "!pip install stable_baselines3\n",
        "!pip install lightsim2grid"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93964d8",
      "metadata": {
        "id": "a93964d8"
      },
      "source": [
        "## 2 Create an environment, and train a first policy\n",
        "\n",
        "In this section we quickly show :\n",
        "\n",
        "- how to create the gym environment, which is an instance from `Grid2opEnvWrapper` defined above\n",
        "- how to train a PPO policy using stable baselines3\n",
        "\n",
        "This part, for stable baselines is really small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "38629107",
      "metadata": {
        "id": "38629107"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from grid2op import make\n",
        "from grid2op.gym_compat import GymEnv\n",
        "from gymnasium import Env\n",
        "from gymnasium.utils.env_checker import check_env\n",
        "from gymnasium.spaces import Discrete, MultiDiscrete, Box\n",
        "import grid2op\n",
        "import json\n",
        "from grid2op.gym_compat import GymEnv, BoxGymObsSpace, DiscreteActSpace, BoxGymActSpace, MultiDiscreteActSpace\n",
        "\n",
        "\n",
        "try:\n",
        "    from lightsim2grid import LightSimBackend\n",
        "    bk_cls = LightSimBackend\n",
        "except ImportError as exc:\n",
        "    print(f\"Error: {exc} when importing faster LightSimBackend\")\n",
        "    from grid2op.Backend import PandaPowerBackend\n",
        "    bk_cls = PandaPowerBackend\n",
        "\n",
        "env_name = 'l2rpn_case14_sandbox'\n",
        "env = make(env_name, backend=bk_cls())\n",
        "gym_env = GymEnv(env)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs = env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHEPPTH87A2l",
        "outputId": "4a6efbf2-9208-4cbd-e02c-4e4a3b0b5b89"
      },
      "id": "xHEPPTH87A2l",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gym_env.observation_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJoYShbB7Ilq",
        "outputId": "e0c58f29-256c-495d-a8c3-33525d33c591"
      },
      "id": "bJoYShbB7Ilq",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dict('_shunt_bus': Box(-2147483648, 2147483647, (1,), int32), '_shunt_p': Box(-inf, inf, (1,), float32), '_shunt_q': Box(-inf, inf, (1,), float32), '_shunt_v': Box(-inf, inf, (1,), float32), 'a_ex': Box(0.0, inf, (20,), float32), 'a_or': Box(0.0, inf, (20,), float32), 'actual_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32), 'attention_budget': Box(0.0, inf, (1,), float32), 'current_step': Box(-2147483648, 2147483647, (1,), int32), 'curtailment': Box(0.0, 1.0, (6,), float32), 'curtailment_limit': Box(0.0, 1.0, (6,), float32), 'curtailment_limit_effective': Box(0.0, 1.0, (6,), float32), 'day': Discrete(32), 'day_of_week': Discrete(8), 'delta_time': Box(0.0, inf, (1,), float32), 'duration_next_maintenance': Box(-1, 2147483647, (20,), int32), 'gen_margin_down': Box(0.0, [ 5. 10.  0.  0.  0. 15.], (6,), float32), 'gen_margin_up': Box(0.0, [ 5. 10.  0.  0.  0. 15.], (6,), float32), 'gen_p': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32), 'gen_p_before_curtail': Box(-162.01, [302.01    282.01    232.01001 232.01001 202.01    262.01   ], (6,), float32), 'gen_q': Box(-inf, inf, (6,), float32), 'gen_theta': Box(-180.0, 180.0, (6,), float32), 'gen_v': Box(0.0, inf, (6,), float32), 'hour_of_day': Discrete(24), 'is_alarm_illegal': Discrete(2), 'line_status': MultiBinary(20), 'load_p': Box(-inf, inf, (11,), float32), 'load_q': Box(-inf, inf, (11,), float32), 'load_theta': Box(-180.0, 180.0, (11,), float32), 'load_v': Box(0.0, inf, (11,), float32), 'max_step': Box(-2147483648, 2147483647, (1,), int32), 'minute_of_hour': Discrete(60), 'month': Discrete(13), 'p_ex': Box(-inf, inf, (20,), float32), 'p_or': Box(-inf, inf, (20,), float32), 'q_ex': Box(-inf, inf, (20,), float32), 'q_or': Box(-inf, inf, (20,), float32), 'rho': Box(0.0, inf, (20,), float32), 'target_dispatch': Box([-140. -120.  -70.  -70.  -40. -100.], [140. 120.  70.  70.  40. 100.], (6,), float32), 'thermal_limit': Box(0.0, inf, (20,), float32), 'theta_ex': Box(-180.0, 180.0, (20,), float32), 'theta_or': Box(-180.0, 180.0, (20,), float32), 'time_before_cooldown_line': Box(0, 10, (20,), int32), 'time_before_cooldown_sub': Box(0, 0, (14,), int32), 'time_next_maintenance': Box(-1, 2147483647, (20,), int32), 'time_since_last_alarm': Box(-1, 2147483647, (1,), int32), 'timestep_overflow': Box(-2147483648, 2147483647, (20,), int32), 'topo_vect': Box(-1, 2, (57,), int32), 'v_ex': Box(0.0, inf, (20,), float32), 'v_or': Box(0.0, inf, (20,), float32), 'was_alarm_used_after_game_over': Discrete(2), 'year': Discrete(2100))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "qPO33bdGcYmU",
      "metadata": {
        "id": "qPO33bdGcYmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d8f55a-c386-45d6-b456-1ed070837189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "# creating action space and observation space\n",
        "\n",
        "gym_env.action_space = DiscreteActSpace(env.action_space,\n",
        "                                        attr_to_keep=[\"set_bus\" , \"set_line_status_simple\"])\n",
        "gym_env.observation_space = BoxGymObsSpace(env.observation_space,\n",
        "                                           attr_to_keep=[\"rho\", \"gen_p\", \"gen_q\", \"gen_v\", \"line_status\", \"load_p\", \"load_q\", \"load_v\", \"time_before_cooldown_sub\", \"time_before_cooldown_line\"])\n",
        "\n",
        "\n",
        "policy_kwargs = dict(net_arch=[dict(pi=[500, 1000, 500], vf=[500,1000,500])])\n",
        "\n",
        "sb3_algo1 = PPO(env=gym_env,\n",
        "               learning_rate=5e-5,\n",
        "               policy=\"MlpPolicy\",\n",
        "               policy_kwargs=policy_kwargs,\n",
        "               n_steps=512,\n",
        "               batch_size=16,\n",
        "               n_epochs=10,\n",
        "               clip_range=0.1,\n",
        "               gae_lambda=0.95,\n",
        "               max_grad_norm=0.5,\n",
        "               verbose=True,\n",
        "               )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "BpcaVMsMcZEM",
      "metadata": {
        "id": "BpcaVMsMcZEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aaa82f0-3657-4119-ace1-c47c2834645f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(219)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "gym_env.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "_sIoizWSdHwV",
      "metadata": {
        "id": "_sIoizWSdHwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9cce904-934b-429f-d202-dcee97e36be1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 81.4       ,  79.3       ,   5.3       ,   0.        ,\n",
              "          0.        ,  82.24667   ,  19.496038  ,  71.34023   ,\n",
              "         24.368923  ,  24.368923  ,  24.01807   , -17.27466   ,\n",
              "        142.1       , 142.1       ,  22.        ,  22.        ,\n",
              "         13.200001  , 142.1       ,   1.        ,   1.        ,\n",
              "          1.        ,   1.        ,   1.        ,   1.        ,\n",
              "          1.        ,   1.        ,   1.        ,   1.        ,\n",
              "          1.        ,   1.        ,   1.        ,   1.        ,\n",
              "          1.        ,   1.        ,   1.        ,   1.        ,\n",
              "          1.        ,   1.        ,  21.9       ,  85.8       ,\n",
              "         44.3       ,   6.9       ,  11.9       ,  28.5       ,\n",
              "          8.8       ,   3.5       ,   5.4       ,  12.6       ,\n",
              "         14.4       ,  15.4       ,  59.7       ,  30.8       ,\n",
              "          4.8       ,   8.3       ,  19.4       ,   6.1       ,\n",
              "          2.4       ,   3.9       ,   8.8       ,  10.5       ,\n",
              "        142.1       , 142.1       , 138.66075   , 139.29695   ,\n",
              "         22.        ,  21.13022   ,  21.12955   ,  21.478817  ,\n",
              "         21.571596  ,  21.432823  ,  20.750198  ,   0.34012988,\n",
              "          0.36042336,   0.2721007 ,   0.26722595,   0.8281293 ,\n",
              "          0.26920095,   0.34334618,   0.5315159 ,   0.49516448,\n",
              "          0.7316751 ,   0.28853893,   0.3826594 ,   0.28927472,\n",
              "          0.43187788,   0.39644888,   0.5446019 ,   0.5334674 ,\n",
              "          0.9244734 ,   0.4533958 ,   0.4615403 ,   0.        ,\n",
              "          0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ,   0.        ,   0.        ,   0.        ,\n",
              "          0.        ], dtype=float32),\n",
              " {'time serie id': '/root/data_grid2op/l2rpn_case14_sandbox/chronics/0001'})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "gym_env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "89be6372",
      "metadata": {
        "id": "89be6372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0271b00f-2f34-464d-c415-c6e71a3a55d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3.86     |\n",
            "|    ep_rew_mean     | 173      |\n",
            "| time/              |          |\n",
            "|    fps             | 15       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 33       |\n",
            "|    total_timesteps | 512      |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3.75         |\n",
            "|    ep_rew_mean          | 166          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 12           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 1024         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040791333 |\n",
            "|    clip_fraction        | 0.261        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -5.39        |\n",
            "|    explained_variance   | 0.000253     |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 7.63e+03     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.0357      |\n",
            "|    value_loss           | 2.21e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.02        |\n",
            "|    ep_rew_mean          | 181         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 12          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 122         |\n",
            "|    total_timesteps      | 1536        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004593176 |\n",
            "|    clip_fraction        | 0.304       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -5.38       |\n",
            "|    explained_variance   | 1.01e-05    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 8.92e+03    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.035      |\n",
            "|    value_loss           | 1.72e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.11        |\n",
            "|    ep_rew_mean          | 187         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 12          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 158         |\n",
            "|    total_timesteps      | 2048        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005404662 |\n",
            "|    clip_fraction        | 0.342       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -5.37       |\n",
            "|    explained_variance   | 1.33e-05    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 4.5e+03     |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0366     |\n",
            "|    value_loss           | 1.68e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.23        |\n",
            "|    ep_rew_mean          | 198         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 13          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 195         |\n",
            "|    total_timesteps      | 2560        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004593877 |\n",
            "|    clip_fraction        | 0.29        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -5.36       |\n",
            "|    explained_variance   | 7.75e-06    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 5.04e+03    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0327     |\n",
            "|    value_loss           | 2.07e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.84        |\n",
            "|    ep_rew_mean          | 235         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 13          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 227         |\n",
            "|    total_timesteps      | 3072        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011543136 |\n",
            "|    clip_fraction        | 0.396       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -5.35       |\n",
            "|    explained_variance   | 5.6e-06     |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 1.32e+04    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0324     |\n",
            "|    value_loss           | 2.02e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 4.82        |\n",
            "|    ep_rew_mean          | 235         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 13          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 266         |\n",
            "|    total_timesteps      | 3584        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009975692 |\n",
            "|    clip_fraction        | 0.369       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -5.34       |\n",
            "|    explained_variance   | 3.96e-05    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 7.15e+03    |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0249     |\n",
            "|    value_loss           | 2.83e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.09         |\n",
            "|    ep_rew_mean          | 250          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 13           |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 297          |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062094373 |\n",
            "|    clip_fraction        | 0.299        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -5.32        |\n",
            "|    explained_variance   | 3.28e-06     |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.68e+04     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.0285      |\n",
            "|    value_loss           | 2.61e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.21        |\n",
            "|    ep_rew_mean          | 256         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 13          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 329         |\n",
            "|    total_timesteps      | 4608        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004901012 |\n",
            "|    clip_fraction        | 0.295       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -5.31       |\n",
            "|    explained_variance   | 0.000334    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 1.2e+04     |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0294     |\n",
            "|    value_loss           | 2.72e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 4.88         |\n",
            "|    ep_rew_mean          | 237          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 361          |\n",
            "|    total_timesteps      | 5120         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046809986 |\n",
            "|    clip_fraction        | 0.309        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -5.29        |\n",
            "|    explained_variance   | 0.00792      |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.18e+04     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.0321      |\n",
            "|    value_loss           | 2.28e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.75         |\n",
            "|    ep_rew_mean          | 294          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 390          |\n",
            "|    total_timesteps      | 5632         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032550162 |\n",
            "|    clip_fraction        | 0.173        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -5.28        |\n",
            "|    explained_variance   | 0.00671      |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 3.12e+04     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.0253      |\n",
            "|    value_loss           | 2.58e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.67         |\n",
            "|    ep_rew_mean          | 293          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 419          |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011419357 |\n",
            "|    clip_fraction        | 0.0191       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -5.27        |\n",
            "|    explained_variance   | 0.0271       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.02e+04     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.0124      |\n",
            "|    value_loss           | 3.65e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.57         |\n",
            "|    ep_rew_mean          | 287          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 448          |\n",
            "|    total_timesteps      | 6656         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010708093 |\n",
            "|    clip_fraction        | 0.0174       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -5.26        |\n",
            "|    explained_variance   | 0.0272       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.65e+04     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.0114      |\n",
            "|    value_loss           | 3.29e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.59          |\n",
            "|    ep_rew_mean          | 279           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 14            |\n",
            "|    iterations           | 14            |\n",
            "|    time_elapsed         | 478           |\n",
            "|    total_timesteps      | 7168          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00084310956 |\n",
            "|    clip_fraction        | 0.00723       |\n",
            "|    clip_range           | 0.1           |\n",
            "|    entropy_loss         | -5.25         |\n",
            "|    explained_variance   | 0.0118        |\n",
            "|    learning_rate        | 5e-05         |\n",
            "|    loss                 | 9.42e+03      |\n",
            "|    n_updates            | 130           |\n",
            "|    policy_gradient_loss | -0.00993      |\n",
            "|    value_loss           | 3.11e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.16         |\n",
            "|    ep_rew_mean          | 259          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 15           |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 509          |\n",
            "|    total_timesteps      | 7680         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034155622 |\n",
            "|    clip_fraction        | 0.118        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -5.24        |\n",
            "|    explained_variance   | 0.0233       |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.79e+04     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.0198      |\n",
            "|    value_loss           | 2.65e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.59         |\n",
            "|    ep_rew_mean          | 288          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 15           |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 538          |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012356275 |\n",
            "|    clip_fraction        | 0.0473       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -5.22        |\n",
            "|    explained_variance   | -0.00161     |\n",
            "|    learning_rate        | 5e-05        |\n",
            "|    loss                 | 1.77e+04     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.017       |\n",
            "|    value_loss           | 2.9e+04      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.61        |\n",
            "|    ep_rew_mean          | 286         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 566         |\n",
            "|    total_timesteps      | 8704        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000190472 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -5.22       |\n",
            "|    explained_variance   | 0.059       |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 2.08e+04    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00413    |\n",
            "|    value_loss           | 2.9e+04     |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.54          |\n",
            "|    ep_rew_mean          | 282           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 15            |\n",
            "|    iterations           | 18            |\n",
            "|    time_elapsed         | 595           |\n",
            "|    total_timesteps      | 9216          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00041323248 |\n",
            "|    clip_fraction        | 0.00605       |\n",
            "|    clip_range           | 0.1           |\n",
            "|    entropy_loss         | -5.22         |\n",
            "|    explained_variance   | 0.0749        |\n",
            "|    learning_rate        | 5e-05         |\n",
            "|    loss                 | 1.93e+04      |\n",
            "|    n_updates            | 170           |\n",
            "|    policy_gradient_loss | -0.00735      |\n",
            "|    value_loss           | 2.87e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.6           |\n",
            "|    ep_rew_mean          | 279           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 15            |\n",
            "|    iterations           | 19            |\n",
            "|    time_elapsed         | 624           |\n",
            "|    total_timesteps      | 9728          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016754167 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.1           |\n",
            "|    entropy_loss         | -5.21         |\n",
            "|    explained_variance   | 0.0397        |\n",
            "|    learning_rate        | 5e-05         |\n",
            "|    loss                 | 1.05e+04      |\n",
            "|    n_updates            | 180           |\n",
            "|    policy_gradient_loss | -0.00429      |\n",
            "|    value_loss           | 3.08e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.48          |\n",
            "|    ep_rew_mean          | 278           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 15            |\n",
            "|    iterations           | 20            |\n",
            "|    time_elapsed         | 654           |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014377467 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.1           |\n",
            "|    entropy_loss         | -5.21         |\n",
            "|    explained_variance   | 0.0931        |\n",
            "|    learning_rate        | 5e-05         |\n",
            "|    loss                 | 1.77e+04      |\n",
            "|    n_updates            | 190           |\n",
            "|    policy_gradient_loss | -0.00406      |\n",
            "|    value_loss           | 2.63e+04      |\n",
            "-------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x79bb577b04c0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sb3_algo1.learn(total_timesteps=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a8f9717",
      "metadata": {
        "id": "3a8f9717"
      },
      "source": [
        "## 3 Evaluate the trained agent\n",
        "\n",
        "This notebook is a simple quick introduction for stable baselines only. So we don't really recall everything that has been said previously.\n",
        "\n",
        "Please consult the section `0) Recommended initial steps` of the notebook [11_IntegrationWithExistingRLFrameworks](./11_IntegrationWithExistingRLFrameworks.ipynb) for more information.\n",
        "\n",
        "**TLD;DR** grid2op offers the possibility to test your agent on scenarios / episodes different from the one it has been trained. We greatly encourage you to use this functionality.\n",
        "\n",
        "There are two main ways to evaluate your agent:\n",
        "\n",
        "- you stay in the \"gymnasium\" world (see [here](#31-staying-in-the-gymnasium-ecosystem) ) and you evaluate your policy directly just like you would any other gymnasium compatible environment. Simple, easy but without support for some grid2op features\n",
        "- you \"get back\" to the \"grid2op\" world (detailed [here](#32-using-the-grid2op-ecosystem)) by \"converting\" your NN policy into something that is able to output grid2op like action. This introduces yet again a \"wrapper\" but you can benefit from all grid2op features, such as the `Runner` to save an inspect what your policy has done.\n",
        "\n",
        "<font color='red'> We show here just a simple examples to \"get easily started\". For much better working agents, you can have a look at l2rpn-baselines code. There you have classes that maps the environment, the agents etc. to grid2op directly (you don't have to copy paste any wrapper).</font>\n",
        "\n",
        "\n",
        "\n",
        "### 3.1 staying in the gymnasium ecosystem\n",
        "\n",
        "You can do pretty much what you want, but you have to do it yourself, or use any of the \"Wrappers\" available in gymnasium https://gymnasium.farama.org/main/api/wrappers/ (*eg* https://gymnasium.farama.org/main/api/wrappers/misc_wrappers/#gymnasium.wrappers.RecordEpisodeStatistics) or in your RL framework.\n",
        "\n",
        "For the sake of simplicity, we show how to do things \"manually\" even though we do not recommend to do it like that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "da0e7990",
      "metadata": {
        "id": "da0e7990",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7863899c-e26f-406a-a091-c6b94d10519b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"0\": {\n",
            "        \"time serie id\": 0,\n",
            "        \"time serie folder\": \"/root/data_grid2op/l2rpn_case14_sandbox/chronics/0000\",\n",
            "        \"env seed\": 200,\n",
            "        \"agent seed\": 200,\n",
            "        \"steps survived\": 1089,\n",
            "        \"cum reward\": 69109.22798919678\n",
            "    },\n",
            "    \"1\": {\n",
            "        \"time serie id\": 1,\n",
            "        \"time serie folder\": \"/root/data_grid2op/l2rpn_case14_sandbox/chronics/0001\",\n",
            "        \"env seed\": 500,\n",
            "        \"agent seed\": 200,\n",
            "        \"steps survived\": 806,\n",
            "        \"cum reward\": 51495.505378723145\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"time serie id\": 2,\n",
            "        \"time serie folder\": \"/root/data_grid2op/l2rpn_case14_sandbox/chronics/0002\",\n",
            "        \"env seed\": 1000,\n",
            "        \"agent seed\": 200,\n",
            "        \"steps survived\": 395,\n",
            "        \"cum reward\": 27859.206676483154\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"time serie id\": 4,\n",
            "        \"time serie folder\": \"/root/data_grid2op/l2rpn_case14_sandbox/chronics/0004\",\n",
            "        \"env seed\": 2000,\n",
            "        \"agent seed\": 200,\n",
            "        \"steps survived\": 802,\n",
            "        \"cum reward\": 52641.856452941895\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "nb_episode_test = 4\n",
        "seeds_test_env = (200,500,1000,2000)    # same size as nb_episode_test\n",
        "seeds_test_agent = (103, 114, 145, 149)  # same size as nb_episode_test\n",
        "ts_ep_test =  (0, 1,2,4)       # same size as nb_episode_test\n",
        "ep_infos = {}  # information that will be saved\n",
        "\n",
        "\n",
        "for ep_test_num in range(nb_episode_test):\n",
        "    init_obs, init_infos = gym_env.reset(seed=seeds_test_env[ep_test_num],\n",
        "                                         options={\"time serie id\": ts_ep_test[ep_test_num]})\n",
        "    sb3_algo1.set_random_seed(seeds_test_agent[ep_test_num])\n",
        "    done = False\n",
        "    cum_reward = 0\n",
        "    step_survived = 0\n",
        "    obs = init_obs\n",
        "    while not done:\n",
        "        act, _states = sb3_algo1.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = gym_env.step(act)\n",
        "        step_survived += 1\n",
        "        cum_reward += float(reward)\n",
        "        done = terminated or truncated\n",
        "    ep_infos[ep_test_num] = {\"time serie id\": ts_ep_test[ep_test_num],\n",
        "                             \"time serie folder\": gym_env.init_env.chronics_handler.get_id(),\n",
        "                             \"env seed\": seeds_test_env[ep_test_num],\n",
        "                             \"agent seed\": seeds_test_agent[ep_test_num],\n",
        "                             \"steps survived\": step_survived,\n",
        "                             \"cum reward\": cum_reward}\n",
        "\n",
        "print(json.dumps(ep_infos, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalised observation\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "\n",
        "vec_env = DummyVecEnv([lambda: gym_env])\n",
        "vec_env = VecNormalize(vec_env, norm_obs=True, norm_reward=True)\n",
        "\n",
        "\n",
        "policy_kwargs = dict(net_arch=[dict(pi=[500, 1000, 500], vf=[500,1000,500])])\n",
        "\n",
        "nn_model = PPO(env=vec_env,\n",
        "               learning_rate=5e-5,\n",
        "               policy=\"MlpPolicy\",\n",
        "               policy_kwargs=policy_kwargs , #{\"net_arch\": [100, 100, 100]},\n",
        "               n_steps=512,\n",
        "               batch_size=16,\n",
        "               verbose=True,\n",
        "               )\n",
        "nn_model.learn(total_timesteps=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFqKPVGnHXcC",
        "outputId": "2e79a175-c193-4612-c07a-d0d40fcc436f"
      },
      "id": "DFqKPVGnHXcC",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------\n",
            "| time/              |     |\n",
            "|    fps             | 17  |\n",
            "|    iterations      | 1   |\n",
            "|    time_elapsed    | 28  |\n",
            "|    total_timesteps | 512 |\n",
            "----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 68          |\n",
            "|    total_timesteps      | 1024        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026200553 |\n",
            "|    clip_fraction        | 0.345       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.38       |\n",
            "|    explained_variance   | -0.208      |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.0442      |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0936     |\n",
            "|    value_loss           | 1           |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 1536        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.029651552 |\n",
            "|    clip_fraction        | 0.463       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.37       |\n",
            "|    explained_variance   | 0.146       |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | -0.0374     |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.109      |\n",
            "|    value_loss           | 0.519       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 143         |\n",
            "|    total_timesteps      | 2048        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031637482 |\n",
            "|    clip_fraction        | 0.478       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.36       |\n",
            "|    explained_variance   | 0.0349      |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | -0.0546     |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.107      |\n",
            "|    value_loss           | 0.706       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 180         |\n",
            "|    total_timesteps      | 2560        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.033478934 |\n",
            "|    clip_fraction        | 0.514       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.35       |\n",
            "|    explained_variance   | 0.0271      |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.166       |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.112      |\n",
            "|    value_loss           | 0.736       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 213         |\n",
            "|    total_timesteps      | 3072        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.037713364 |\n",
            "|    clip_fraction        | 0.537       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.32       |\n",
            "|    explained_variance   | -0.0852     |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | -0.00699    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.113      |\n",
            "|    value_loss           | 0.544       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 249         |\n",
            "|    total_timesteps      | 3584        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.036480457 |\n",
            "|    clip_fraction        | 0.514       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.31       |\n",
            "|    explained_variance   | 0.0199      |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | -0.0752     |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.107      |\n",
            "|    value_loss           | 0.543       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 284         |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.038461283 |\n",
            "|    clip_fraction        | 0.53        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.28       |\n",
            "|    explained_variance   | 0.083       |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | -0.00441    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.11       |\n",
            "|    value_loss           | 0.638       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 14         |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 317        |\n",
            "|    total_timesteps      | 4608       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03808062 |\n",
            "|    clip_fraction        | 0.521      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.26      |\n",
            "|    explained_variance   | 0.0725     |\n",
            "|    learning_rate        | 5e-05      |\n",
            "|    loss                 | 0.0388     |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.11      |\n",
            "|    value_loss           | 0.695      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 350         |\n",
            "|    total_timesteps      | 5120        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.040173233 |\n",
            "|    clip_fraction        | 0.533       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.25       |\n",
            "|    explained_variance   | -0.0544     |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.139       |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.114      |\n",
            "|    value_loss           | 0.618       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 14         |\n",
            "|    iterations           | 11         |\n",
            "|    time_elapsed         | 382        |\n",
            "|    total_timesteps      | 5632       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04136166 |\n",
            "|    clip_fraction        | 0.556      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.22      |\n",
            "|    explained_variance   | 0.11       |\n",
            "|    learning_rate        | 5e-05      |\n",
            "|    loss                 | -0.0513    |\n",
            "|    n_updates            | 100        |\n",
            "|    policy_gradient_loss | -0.113     |\n",
            "|    value_loss           | 0.501      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 410         |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.041573547 |\n",
            "|    clip_fraction        | 0.554       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.18       |\n",
            "|    explained_variance   | 0.18        |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.167       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.115      |\n",
            "|    value_loss           | 0.65        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 15         |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 442        |\n",
            "|    total_timesteps      | 6656       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03753174 |\n",
            "|    clip_fraction        | 0.517      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.15      |\n",
            "|    explained_variance   | 0.167      |\n",
            "|    learning_rate        | 5e-05      |\n",
            "|    loss                 | 0.126      |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.11      |\n",
            "|    value_loss           | 0.72       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 470         |\n",
            "|    total_timesteps      | 7168        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.040771976 |\n",
            "|    clip_fraction        | 0.55        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.11       |\n",
            "|    explained_variance   | 0.145       |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.0292      |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.111      |\n",
            "|    value_loss           | 0.624       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 499         |\n",
            "|    total_timesteps      | 7680        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.039513346 |\n",
            "|    clip_fraction        | 0.53        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.05       |\n",
            "|    explained_variance   | -0.00967    |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | -0.0312     |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.109      |\n",
            "|    value_loss           | 0.733       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 527         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.041268844 |\n",
            "|    clip_fraction        | 0.549       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5          |\n",
            "|    explained_variance   | 0.232       |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.164       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.11       |\n",
            "|    value_loss           | 0.71        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 554         |\n",
            "|    total_timesteps      | 8704        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.038453966 |\n",
            "|    clip_fraction        | 0.515       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.93       |\n",
            "|    explained_variance   | 0.0452      |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 1.05        |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.102      |\n",
            "|    value_loss           | 0.936       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 582         |\n",
            "|    total_timesteps      | 9216        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.042981263 |\n",
            "|    clip_fraction        | 0.564       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.87       |\n",
            "|    explained_variance   | 0.182       |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | 0.211       |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.111      |\n",
            "|    value_loss           | 0.68        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 16          |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 606         |\n",
            "|    total_timesteps      | 9728        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.045167983 |\n",
            "|    clip_fraction        | 0.569       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.79       |\n",
            "|    explained_variance   | 0.151       |\n",
            "|    learning_rate        | 5e-05       |\n",
            "|    loss                 | -0.029      |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.109      |\n",
            "|    value_loss           | 0.568       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 16        |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 629       |\n",
            "|    total_timesteps      | 10240     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0402232 |\n",
            "|    clip_fraction        | 0.485     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.67     |\n",
            "|    explained_variance   | 0.185     |\n",
            "|    learning_rate        | 5e-05     |\n",
            "|    loss                 | -0.0182   |\n",
            "|    n_updates            | 190       |\n",
            "|    policy_gradient_loss | -0.0995   |\n",
            "|    value_loss           | 0.906     |\n",
            "---------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x79bb55887460>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_episode_test = 4\n",
        "seeds_test_env = (200,500,1000,2000)    # same size as nb_episode_test\n",
        "seeds_test_agent = (103, 114, 145, 149)  # same size as nb_episode_test\n",
        "ts_ep_test =  (0, 1,2,3)       # same size as nb_episode_test\n",
        "ep_infos = {}  # information that will be saved\n",
        "\n",
        "\n",
        "for ep_test_num in range(nb_episode_test):\n",
        "    init_obs, init_infos = gym_env.reset(seed=seeds_test_env[ep_test_num],\n",
        "                                         options={\"time serie id\": ts_ep_test[ep_test_num]})\n",
        "    nn_model.set_random_seed(seeds_test_agent[ep_test_num])\n",
        "    done = False\n",
        "    cum_reward = 0\n",
        "    step_survived = 0\n",
        "    obs = init_obs\n",
        "    while not done:\n",
        "        act, _states = nn_model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = gym_env.step(act)\n",
        "        step_survived += 1\n",
        "        cum_reward += float(reward)\n",
        "        done = terminated or truncated\n",
        "    ep_infos[ep_test_num] = {\"time serie id\": ts_ep_test[ep_test_num],\n",
        "                             \"time serie folder\": gym_env.init_env.chronics_handler.get_id(),\n",
        "                             \"env seed\": seeds_test_env[ep_test_num],\n",
        "                             \"agent seed\": seeds_test_agent[ep_test_num],\n",
        "                             \"steps survived\": step_survived,\n",
        "                             \"cum reward\": cum_reward}\n",
        "\n",
        "print(json.dumps(ep_infos, indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I70DwH9KlmT",
        "outputId": "548ac866-597e-48d5-a913-041c407b57d5"
      },
      "id": "4I70DwH9KlmT",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"0\": {\n",
            "        \"time serie id\": 0,\n",
            "        \"time serie folder\": \"/root/data_grid2op/l2rpn_case14_sandbox/chronics/0000\",\n",
            "        \"env seed\": 200,\n",
            "        \"agent seed\": 103,\n",
            "        \"steps survived\": 1091,\n",
            "        \"cum reward\": 69236.51405715942\n",
            "    },\n",
            "    \"1\": {\n",
            "        \"time serie id\": 1,\n",
            "        \"time serie folder\": \"/root/data_grid2op/l2rpn_case14_sandbox/chronics/0001\",\n",
            "        \"env seed\": 500,\n",
            "        \"agent seed\": 114,\n",
            "        \"steps survived\": 807,\n",
            "        \"cum reward\": 51564.479511260986\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"time serie id\": 2,\n",
            "        \"time serie folder\": \"/root/data_grid2op/l2rpn_case14_sandbox/chronics/0002\",\n",
            "        \"env seed\": 1000,\n",
            "        \"agent seed\": 145,\n",
            "        \"steps survived\": 3001,\n",
            "        \"cum reward\": 191833.17527008057\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"time serie id\": 3,\n",
            "        \"time serie folder\": \"/root/data_grid2op/l2rpn_case14_sandbox/chronics/0003\",\n",
            "        \"env seed\": 2000,\n",
            "        \"agent seed\": 149,\n",
            "        \"steps survived\": 3,\n",
            "        \"cum reward\": 113.81636047363281\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bRHkcG69Nt3-"
      },
      "id": "bRHkcG69Nt3-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}